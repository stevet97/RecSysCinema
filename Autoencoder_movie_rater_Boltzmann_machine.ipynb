{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Recommender system"
      ],
      "metadata": {
        "id": "48ICZWtL3GHc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Importing the libraries"
      ],
      "metadata": {
        "id": "T6n4UfJJ3D_2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "from torch.autograd import Variable"
      ],
      "metadata": {
        "id": "kTWal1je6nPX"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Mount Google Drive / Load datasets"
      ],
      "metadata": {
        "id": "qerqrSN0fYuP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LY_qNJVqcBgs",
        "outputId": "e301b42e-d4bf-43cd-e93b-6836d3d35a90"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# !ls /content/drive/MyDrive : For checking the files\n",
        "\n",
        "# Define the file paths for movies.dat and users.dat\n",
        "movies_file_path = '/content/drive/MyDrive/movies.dat'\n",
        "ratings_file_path = '/content/drive/MyDrive/ratings.dat'\n",
        "users_file_path = '/content/drive/MyDrive/users.dat'\n",
        "\n",
        "#Load datasets\n",
        "training_set = pd.read_csv('/content/drive/MyDrive/u1.base', delimiter = '\\t', header = None)\n",
        "test_set = pd.read_csv('/content/drive/MyDrive/u1.test', delimiter = '\\t', header = None)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Convert to NumPy arrays"
      ],
      "metadata": {
        "id": "XZdApv5U-79S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_set = training_set.iloc[:, :3].to_numpy()\n",
        "test_set = test_set.iloc[:, :3].to_numpy()\n",
        "\n",
        "#Recalculate the number of users and movies\n",
        "nb_users = int(max(max(training_set[:, 0]), max(test_set[:, 0])))\n",
        "nb_movies = int(max(max(training_set[:, 1]), max(test_set[:, 1])))\n",
        "print(nb_users, nb_movies)\n"
      ],
      "metadata": {
        "id": "39WwSzdd9hOb",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd4bc435-7feb-45f5-bb94-593abec8491e"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "943 1682\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Get the number of users and movies"
      ],
      "metadata": {
        "id": "-Zc7nZ6VweC8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nb_users = int(max(max(training_set[:, 0]), max(test_set[:, 0])))\n",
        "nb_movies = int(max(max(training_set[:, 1]), max(test_set[:, 1])))\n",
        "print(nb_users, nb_movies)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NpvC3lpZwoUq",
        "outputId": "e47e15c2-0843-4afa-c0a8-ec88b0a1f8ea"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "943 1682\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Convert function"
      ],
      "metadata": {
        "id": "nUrF-gy_raBs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def convert(data):\n",
        "    new_data = []\n",
        "    for id_users in range(1, nb_users + 1):\n",
        "        id_movies = data[:, 1][data[:, 0] == id_users].astype(int)\n",
        "        id_ratings = data[:, 2][data[:, 0] == id_users]\n",
        "        ratings = np.zeros(nb_movies)\n",
        "        if len(id_movies) > 0:\n",
        "            ratings[id_movies - 1] = id_ratings\n",
        "        new_data.append(ratings)\n",
        "    return np.array(new_data)\n"
      ],
      "metadata": {
        "id": "AQBnq2PjrZSr"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Convert datasets"
      ],
      "metadata": {
        "id": "KK5DyHlhxapn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_set = convert(training_set)\n",
        "test_set = convert(test_set)"
      ],
      "metadata": {
        "id": "qIK6AjxWxd46"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Converting ratings to pytorch tensors"
      ],
      "metadata": {
        "id": "ttS1knZInBIK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_set = torch.FloatTensor(training_set)\n",
        "test_set = torch.FloatTensor(test_set)"
      ],
      "metadata": {
        "id": "pjjaNtEBxSPo"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Converting the ratings into binary ratings 1 (liked) or 0 (not liked)"
      ],
      "metadata": {
        "id": "eSYhIZlDevPm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_set[training_set == 0] = -1\n",
        "training_set[training_set == 1] = 0\n",
        "training_set[training_set == 2] = 0\n",
        "training_set[training_set >= 3] = 1\n",
        "\n",
        "test_set[test_set == 0] = -1\n",
        "test_set[test_set == 1] = 0\n",
        "test_set[test_set == 2] = 0\n",
        "test_set[test_set >= 3] = 1\n"
      ],
      "metadata": {
        "id": "J-VLOcDEjTGJ"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Set up the RBM architecture"
      ],
      "metadata": {
        "id": "jVpLttm30pFK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RBM(nn.Module):\n",
        "    def __init__(self, n_visible, n_hidden):\n",
        "        super(RBM, self).__init__()\n",
        "        # Initialize weights and biases\n",
        "        self.W = nn.Parameter(torch.randn(n_hidden, n_visible) * 0.1)  # Weights\n",
        "        self.a = nn.Parameter(torch.zeros(1, n_hidden))  # Bias for hidden layer\n",
        "        self.b = nn.Parameter(torch.zeros(1, n_visible))  # Bias for visible layer\n",
        "\n",
        "    # Sample hidden nodes given visible nodes\n",
        "    def sample_h(self, x):\n",
        "        wx = torch.mm(x, self.W.t()) + self.a\n",
        "        prob_h_given_v = torch.sigmoid(wx)  # Probability of hidden node being activated\n",
        "        return prob_h_given_v, torch.bernoulli(prob_h_given_v)\n",
        "\n",
        "    # Sample visible nodes given hidden nodes\n",
        "    def sample_v(self, y):\n",
        "        wy = torch.mm(y, self.W) + self.b\n",
        "        prob_v_given_h = torch.sigmoid(wy)  # Probability of visible node being activated\n",
        "        return prob_v_given_h, torch.bernoulli(prob_v_given_h)\n",
        "\n",
        "    # Forward pass: Gibbs Sampling\n",
        "    def forward(self, x):\n",
        "        prob_h_given_v, h_sample = self.sample_h(x)\n",
        "        prob_v_given_h, v_sample = self.sample_v(h_sample)\n",
        "        return prob_v_given_h, v_sample\n",
        ""
      ],
      "metadata": {
        "id": "UD6IZv0Ek67Q"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Initialize the RBM"
      ],
      "metadata": {
        "id": "-orm6JbG3sYG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Set the number of neurons in the visible and hidden layers\n",
        "\n",
        "n_visible = nb_movies #Number of movies (visible layer size)\n",
        "n_hidden = 100 #Number of hidden neurons (customizable)\n",
        "\n",
        "rbm = RBM(n_visible, n_hidden)\n",
        "\n",
        "#Check that the RBM methods are working\n",
        "print(rbm.sample_h)\n",
        "print(rbm.sample_v)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WKQT-J2z3ziK",
        "outputId": "5ae9c38c-a1e4-4d3c-88ff-79fdfd184ee7"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<bound method RBM.sample_h of RBM()>\n",
            "<bound method RBM.sample_v of RBM()>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Defining the Training Process"
      ],
      "metadata": {
        "id": "C6ay-uuJ4RTB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Training process involves reconstructing the data and optimizing the weights and biases\n",
        "#contrastive divergence used for training\n",
        "\n",
        "def train_rbm(rbm, data, epochs=10, batch_size=64, learning_rate=0.01):\n",
        "    optimizer = torch.optim.SGD([rbm.W, rbm.a, rbm.b], lr=learning_rate)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        train_loss = 0\n",
        "        s = 0.0\n",
        "\n",
        "        for i in range(0, len(data) - batch_size, batch_size):\n",
        "            batch = data[i:i + batch_size]\n",
        "            v0 = batch\n",
        "            # Forward pass (Gibbs Sampling)\n",
        "            prob_h_given_v, h_sample = rbm.sample_h(v0)\n",
        "            prob_v_given_h, v_sample = rbm.sample_v(h_sample)\n",
        "\n",
        "            # Compute the loss (reconstruction error)\n",
        "            v1 = v_sample\n",
        "            h1, _ = rbm.sample_h(v1)\n",
        "\n",
        "            # Update weights and biases\n",
        "            optimizer.zero_grad()\n",
        "            rbm.W.grad = torch.mm(h_sample.t(), v0) - torch.mm(h1.t(), v1)\n",
        "            rbm.a.grad = torch.sum(h_sample - h1, 0, keepdim = True) #preserve the dimension\n",
        "            rbm.b.grad = torch.sum(v0 - v1, 0, keepdim = True) #preserve the dimension\n",
        "\n",
        "            optimizer.step()\n",
        "\n",
        "            # Compute reconstruction loss\n",
        "            train_loss += torch.mean(torch.abs(v0[v0 >= 0] - v1[v0 >= 0]))\n",
        "            s += 1.0\n",
        "\n",
        "        print(f'Epoch: {epoch + 1}, Loss: {train_loss / s}')\n",
        "\n"
      ],
      "metadata": {
        "id": "K5Q56gU44TXy"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Train the RBM"
      ],
      "metadata": {
        "id": "77QIM-5q9OJU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_rbm(rbm, training_set, epochs=10, batch_size=64, learning_rate=0.01)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "drNh-KUw4awo",
        "outputId": "f56f122b-5095-41b8-de09-6f6c49e3b310"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, Loss: 0.22065843641757965\n",
            "Epoch: 2, Loss: 0.1749064028263092\n",
            "Epoch: 3, Loss: 0.1749064028263092\n",
            "Epoch: 4, Loss: 0.1749064028263092\n",
            "Epoch: 5, Loss: 0.1749064028263092\n",
            "Epoch: 6, Loss: 0.1749064028263092\n",
            "Epoch: 7, Loss: 0.1749064028263092\n",
            "Epoch: 8, Loss: 0.1749064028263092\n",
            "Epoch: 9, Loss: 0.1749064028263092\n",
            "Epoch: 10, Loss: 0.1749064028263092\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Test the RBM"
      ],
      "metadata": {
        "id": "QuFJ9naK9qES"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_rbm(rbm, training_set, test_set):\n",
        "  test_loss = 0\n",
        "  s = 0.0\n",
        "\n",
        "  for i in range(len(test_set)):\n",
        "    v = training_set[i:i + 1]\n",
        "    vt = test_set[i:i + 1]\n",
        "    if len(vt[vt >= 0]) > 0: #Avoid missing ratings\n",
        "      _, h = rbm.sample_h(v)\n",
        "      prob_v, _ = rbm.sample_v(h)\n",
        "      test_loss += torch.mean(torch.abs(vt[vt >= 0] - prob_v[vt >= 0]))\n",
        "      s += 1.0\n",
        "\n",
        "  print(f'Test Loss: {test_loss / s}')"
      ],
      "metadata": {
        "id": "i1gg1V5V9ZwR"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Run the test"
      ],
      "metadata": {
        "id": "RKoQQ_4DAWWX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_rbm(rbm, training_set, test_set)\n",
        "\n",
        "#NOTE ON NEXT STEPS: Fine-tune the hyperparameters:\n",
        "#- Increase the number of epochs\n",
        "#- Decrease the learning rate\n",
        "#- Increase the batch size\n",
        "\n",
        "#Analyze the results to understand the performance of the RBM\n",
        "#compare the predictions with the actual ratings to evaluate the model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yO5k0ptOAXfc",
        "outputId": "fc555589-b83a-413a-a887-a22e3e04105b"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.15892033278942108\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Save the model"
      ],
      "metadata": {
        "id": "SEeJiVVgA2kt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(rbm.state_dict(), 'rbm_model.pth')"
      ],
      "metadata": {
        "id": "9NgDMxinA1_L"
      },
      "execution_count": 80,
      "outputs": []
    }
  ]
}